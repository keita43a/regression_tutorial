# 単回帰分析 {#simpleregression}


## ２つの変数の関係

実証分析において重要な問いとして「XがYに影響を与えるか」というものである。
例えば、最低賃金を上げると雇用率に影響を与えるか？生徒教員比を減らすと生徒のテストのパフォーマンスはよくなるか？などである。
Xが政策的に変更できる変数であり、Yがなにか経済・社会的に重要な変数ならば、Xを増やす/減らすことでYに影響を与えられる、という政策含意が得られる。

まずは、そもそも2つの変数に統計的な関係があるかを見ていこう。

### 共分散

共分散は直接解釈するとXの偏差とYの偏差の積の平均、となる。

例えば、次のような5人の国語と算数の試験の点数のデータがあるとする。


```{r, echo=FALSE}
# テストデータの作成
test <- data.frame(student = c("A","B","C","D","E"),
                   kokugo = c(50, 50, 80, 70, 90),
                   sugaku = c(52, 75, 62, 89, 99))

# テストデータの表示
test
```

それぞれの平均を求めてみよう。

```{r}
test |> summarise(kokugo_average = mean(kokugo),
                  sugaku_average = mean(sugaku))

```

それぞれ国語が68点、算数が75.4点という結果である。

Aさんはそれぞれの科目で、平均からどれぐらい離れているか？言い換えると、偏差はいくつだろうか。

$$
 国語の偏差 = 50-68 = -18\\
 数学の偏差 = 52-75.4 = -23.4
$$
となる。

偏差の積とは、$-18\times-23.4$なので$421.2$になる。
5人の偏差とその積をとってみよう。

```{r}
test |> 
  mutate(kokugo_hensa = kokugo - mean(kokugo),
         sugaku_hensa = sugaku - mean(sugaku)) |>
  mutate(hensa_seki = kokugo_hensa*sugaku_hensa)
```

ここで、あることに気づいた人もいるかもしれない。
偏差の積は、**どちらもよい**か**どちらも悪い**点数なら、正の数で大きくなり、どちらかが悪くてもう一つがよいと、負の数になる。
このケースで言えば、Aさん（どちらも悪い）や、Eさん（どちらもよい）は、偏差の積が正で大きく、Cさん（国語は良いが数学は悪い）は、偏差の積が負になっている。

この平均を取るということは、どちらも悪い・どちらも良い、という傾向があるか、どちらかが悪いともう片方がよい、という傾向があるかということがわかるということである。

偏差の積の平均を取ってみよう。

```{r}
test |> 
  mutate(kokugo_hensa = kokugo - mean(kokugo),
         sugaku_hensa = sugaku - mean(sugaku)) |>
  mutate(hensa_seki = kokugo_hensa*sugaku_hensa) |>
  summarise(hensa_seki_average = mean(hensa_seki))
```
ここでは、162.8という正の数となった。

この数字（2つの変数の偏差の積の平均）を**共分散**と呼び、2つの変数の関係性を測る指標となる。

一般に共分散が正であれば、正の関係がある（Xが大きいときYも大きい傾向がある）、負であれば負の関係がある（Xが大きいとき、Yが小さい傾向がある）。

上の例では、国語の成績がいい人は数学の成績がいい傾向がある、ということになる。


共分散の定義は、以下のような式で定義できる。

$$\sigma_{xy} = \frac{1}{n}\sum^{n}_{i=1}(x_i - \bar{x})(y_i - \bar{y})$$

Rでは、`cov()`という関数が用意されているが、不偏共分散を推定する関数である。そのため、サンプルサイズが小さい上のようなケースでは、$n$で割った場合と大きく異なる数字が出る。

```{r}
test |> summarise(kyoubunsan = cov(kokugo, sugaku))
```


### 相関係数

共分散は2つの変数の関係を見る指標になると述べたが、実際にはあまり使われない。
その理由は、共分散は単位に依存するからである。
例えば、身長と体重のデータがあるとして、身長とmで測るのか、cmで測るのかで共分散は大きく異なる。

しかし、そもそものデータで標準化すれば、単位の問題はなくなる。

先に定義を提示すると、以下のようになる。

$$
 \rho = \frac{\sigma_{xy}}{\sigma_x \sigma_y} 
$$

言葉で説明すれば、相関係数とは共分散をXとYのそれぞれの標準偏差で割った数字である。
単位が大きければばらつきも大きくなるわけなので、そのばらつき自体で割ってしまえば単位に依存しない偏差を計算できるというわけである。

上のテストデータで計算してみよう。

```{r}
test |> 
  mutate(kokugo_hensa = kokugo - mean(kokugo),
         sugaku_hensa = sugaku - mean(sugaku)) |>
  mutate(hensa_seki = kokugo_hensa*sugaku_hensa) |>
  summarise(hensa_seki_average = mean(hensa_seki),
            kokugo_sd = sd(kokugo),
            sugaku_sd = sd(sugaku),
            soukan_keisu = hensa_seki_average/(kokugo_sd*sugaku_sd))
```

相関係数は**相関の程度**を表す係数であり、$-1$から$1$までの実数を取る。数字が負であれば、負の関係があり、正であれば正の関係がある。絶対値が1に近いほど、その関係が強いことを表している。


### 散布図

相関関係を図で描くと直感的である。

例えば、正の相関関係は以下のような図となる。

```{r, echo=FALSE, message =FALSE}

# Set seed for reproducibility
set.seed(0)

# Function to generate data with specified correlation
generate_data <- function(cor, n = 100) {
  x <- rnorm(n)
  y <- cor * x + rnorm(n) * sqrt(1 - cor^2)
  data.frame(x = x, y = y)
}

# Generate data for different correlations
data_09 <- generate_data(0.9)
data_05 <- generate_data(0.5)
data_02 <- generate_data(0.2)

# Plot function
plot_data <- function(data, cor) {
  ggplot(data, aes(x = x, y = y)) +
    geom_point(alpha = 0.7) +
    ggtitle(paste("相関係数=", cor)) +
    xlab("変数 X") +
    ylab("変数 Y") +
    theme_minimal(base_family="Hirakakupro-w3")
}

# Create plots
plot_09 <- plot_data(data_09, 0.9)
plot_05 <- plot_data(data_05, 0.5)
plot_02 <- plot_data(data_02, 0.2)

plot_09 + plot_05 + plot_02
```


また、負の相関関係がある場合は以下のような形である。

```{r, echo=FALSE, message=FALSE, fig.width=12,fig.height=6}
# Generate data for different correlations
data_n09 <- generate_data(-0.9)
data_n05 <- generate_data(-0.5)
data_n02 <- generate_data(-0.2)

# Create plots
plot_n09 <- plot_data(data_n09, -0.9)
plot_n05 <- plot_data(data_n05, -0.5)
plot_n02 <- plot_data(data_n02, -0.2)

plot_n09 + plot_n05 + plot_n02
```

上の図の観察をまとめると、

- 正の場合は右肩上がり、負の場合は右肩下がりの傾向がある
- 相関関係が強い(相関係数の絶対値が１に近い)ほどばらつきが少ない



## 相関関係と因果関係

ここまでは２つの変数の関係として、相関関係を議論してきた。
しかし、社会科学の実証分析で重要な点として、**相関関係は必ずしも因果関係を意味しない**ということがある。

たとえば、下の図はある年の日ごとのアイスクリームの売上と水難事故の件数だとする。

```{r, echo = FALSE}

set.seed(3)

dat_ice = tibble(
  day = 1:100,
  temp = runif(100, 0, 40),  
  ice = (temp*20 + rnorm(100, 0, 100)) %>% ifelse(. >= 0, ., 0) |> round(2) ,
  accident = ifelse(temp < 10, 0 ,round((temp-10)*2.5 + rnorm(100,0,30))) %>% ifelse(. >= 0, ., 0)
) |>
  mutate(temp = round(temp,1))

write_csv(dat_ice,"data/ice_cream.csv")

ggplot(data=dat_ice) +
  geom_point(aes(x=ice, y=accident)) +
  theme_minimal(base_family = "HiraKakuPro-W3") +
  labs(x="アイスクリームの売上（万円）", y="水難事故の件数")

```

このことから、アイスクリームの売上と水難事故件数には相関関係がありそうだ。実際に計算してみても、相関係数は`r cor(dat_ice$ice,dat_ice$accident)|>round(2)`と計算された。

しかし、この２つの間に**因果関係**はあるだろうか？
例えば、アイスクリームの売上を増やすと水難事故も増えるのだろうか？
では、政策的含意として、アイスクリームの販売に規制をかけて売上を増やさないようにすることで、水難事故を防ぐことはできるのだろうか？

もちろんできない。

この２つの変数の後ろには**気温**という別の変数が隠れている。

```{r, echo=FALSE}

temp_plot_1 <- ggplot(data=dat_ice) +
  geom_point(aes(x=temp, y=ice)) +
  theme_minimal(base_family = "HiraKakuPro-W3") +
  labs(y="アイスクリームの売上（万円）", x="気温（℃）")

temp_plot_2 <- ggplot(data=dat_ice) +
  geom_point(aes(x=temp, y=accident)) +
  theme_minimal(base_family = "HiraKakuPro-W3") +
  labs(y="水難事故件数", x="気温（℃）")

temp_plot_1 + temp_plot_2
```


気温が高ければ、人々はアイスクリームを買って食べるし、川や海にレジャーに行くため水難事故の絶対数も増えてしまう。

しかし、アイスクリームと水難事故には直接の関係はないのである。
このような相関関係を**見せかけの相関**と呼ぶ。


## 回帰分析

回帰分析は、２つ以上の変数があるときに、ある変数Yのばらつきが他の変数によって説明できる関係を定量的に示す式を求めることを目的としている。

経済学の実証分析では、回帰分析を用いて**因果関係**を明らかにしようとすることを目的としている。
しかし、注意しなればいけないのは、ただデータを回帰分析して推定しただけで出てきた結果が必ずしも因果関係とは限らないということである。

まず回帰分析を理解するために、**単回帰分析**から勉強しよう。
単回帰分析とは、説明する側の変数の数が一つである場合の回帰分析である。ここでは２つの変数XとYを考える。

回帰分析では、説明される側の変数Yを**目的変数, 被説明変数, 従属変数**などと呼ぶ。
説明する側の変数Xを**説明変数、独立変数**などと呼ぶ。ここではYを目的変数、Xを説明変数と呼ぶように統一する。

回帰分析はXとYの定量的な関係の構造を求めようとすることである。この構造のことを**モデル**と呼ぶ。
このモデルは、様々な関係が考えられる。これから説明するモデルは**線形回帰**と呼ばれ、直線的な関係があることを前提として推定するが、当然ながら非線形的（Xが増えると、最初はYも増えるが徐々にYが減少するようになる、など）な関係も存在しうる。そういった藻で右派**非線形回帰**と呼ばれる。

もっともシンプルな線形回帰の式が、以下の一次方程式で表される関係である。

$$
 Y = \alpha + \beta X
$$

ここで、$\alpha$と$\beta$は**回帰係数(regression coefficient)**または単に係数と呼ばれる。
YとXの間に、このような線形的な関係があるだろう、という前提で具体的にどのような定量的な関係があるかを推定するのが回帰分析である。

たとえば、上の例で気温とアイスクリームの売上を考えてみる。
気温を$X$, アイスクリームの売上を$Y$と考えると以下のような関係があると考える。

$$
 Y = \alpha + \beta X
$$

ここでは、一般的に気温とアイスクリームの関係は、上の式で説明できると考えるのである。つまり、母集団における関係は上の式で表せられると考える。
しかし、当然ながら、上の式だけでは現実とは一致しない。大まかには、気温が上がればアイスクリームの売上が上がるが、上の式では例えば30度の日の売上はいつもおなじになる。しかし、現実には同じ気温での他の観察されない変数の影響や何らかのランダムな要素で上がり下がりがあるはずである。
そのような要素をすべて**ランダム**な要素として、確率的な事象として扱ってしまう。すると、以下の式が得られる。

$$
 Y = \alpha + \beta X + \varepsilon
$$

この$\varepsilon$は**誤差項**（撹乱項）と呼ばれる。誤差項は、期待値が0, 分散が一定, 異なった誤差項は無相関、という条件を満たす確率変数である。

このように、母集団における関係のモデル化ができたが、統計的推定の項で説明したように、我々は母集団の真の姿はわからない。しかし、手元にはデータ（サンプル）がある。データを使って、これらの係数を推定することで、母集団における関係を把握しようとするのが回帰分析の統計的な手続きである。

変数Yのデータを$y_i$, Xのデータを$x$と表記しよう。$i$は何番目のデータかを表す添字である。
データを用いると我々は以下のような式を推定することになる。

$$
 y_{i} = \alpha + \beta x_{i} + \varepsilon_{i}
$$

どのように推定するかは後に説明するが、データを用いて推定された結果、以下のような結果を得ることになる。

$$
 y_{i} = \hat{\alpha} + \hat{\beta} x_{i} + \hat{e}_{i}
$$

^はハットと読む。このハットは、ここでは「推定値」であることを示す。母集団におけるモデルの係数という知りたいがわからないものの数値を、手元のサンプルを使って推定した結果であることを示している。

また、一番最後の$\varepsilon_{i}$だったものが、$\hat{e}_{i}$に変わっていることに気づいただろうか。
これは、**残差**と呼ばれるもので、誤差項の推定値となるものである。

### Rによる単回帰モデルの推定

まずは、Rで実際にやってみて、結果を解釈しながら理解していこう。

Rで回帰分析をする方法はたくさんあるが、まずはもっともシンプルな方法としてRに標準搭載されている`lm()`関数で推定する。


まずは`simple_reg.R`というスクリプトを作成しよう。

そして、よく使うライブラリを読み込んでおく。

```{r}
library(tidyverse)
```

次に、データを読み込む。

```{r}
dat_ice = read_csv("data/ice_cream.csv")
```

まずはデータを確認する。
```{r}
# データの変数の名前のリスト
names(dat_ice)

# データの冒頭だけ見てチェック
head(dat_ice)
```

それぞれ、day(日), temp(気温), ice (アイスクリームの売上), accident (水難事故件数)というデータが記録されている。

それでは、気温とアイスクリームの売上の関係を見る散布図を描いてみよう。

```{r}
ggplot(data=dat_ice, aes(x = temp, y=ice)) + 
  geom_point()
```

上でも見たように、気温が上がればアイスクリームの売上が上がるという右肩上がりの関係がある。

単回帰分析でやろうとしているのは、この関係を定量的に把握して、線を引くことである。

今書いた`ggplot`のコードに、`geom_smooth(method="lm",se=FALSE)`というレイヤーを加えてみよう。

```{r}
ggplot(data=dat_ice,aes(x = temp, y=ice)) + 
  geom_point() +
  geom_smooth(method="lm",se=FALSE) # 追加！
  
```

青い線が表示された。これは実質的には`ggplot`の機能として、単回帰直線を推定して、それを描画するということを行っている。

では、実際に回帰分析を行ってみよう。
Rでは、回帰分析を行う関数の中で、目的変数と説明変数の関係を`y ~ x`のように波線で挟んで書く。
`data`引数で使うデータを指定し、その中のどの変数をそれぞれ目的変数と説明変数にするかを指定する。
推定した結果は、reg1というオブジェクトに格納してから、表示しよう。

```{r}

reg1 <- lm(ice ~ temp, data = dat_ice)

reg1

```

すると、結果として、Callという部分とCoefficientsという部分に分かれた結果が表示される。
結果はCoefficientsの部分である。
ここでは、(Intercept)というのは切片のことであり、上の式の$\hat{\alpha}$にあたる推定値である。
回帰直線の傾きを表す係数の推定値$\hat{\beta}$は、`temp`の下に表示されている。

すなわち、この結果から、以下のような推定値が得られたことになる。

$$
 y_{i} = 11.37 + 18.69 \times x_{i} + \hat{e}_{i}
$$

これを素直に解釈すると、「気温が１℃上がると、アイスクリームの売上が18.69万円上昇する」ということができる。


### 回帰係数の統計的な推定

まず係数の推定結果を出して、推定することができた。
ここで推定された`reg1`に入っている`lm`オブジェクトは、`summary()`関数を適用することでさらに詳細な内容を見ることができる。

```{r}
summary(reg1)
```
summaryを適用せずに見た結果と違って、Residualsという項目が追加され、またCoefficientsの内容も拡充されているのがわかる。

ここで大事なのは、Coefficientsに表示されている表である。
先ほどと同様に$\hat{\alpha}$と$\hat{\beta}$が表示されているが、推定値以外のものも表示されているために表形式になっている。

`Estimate`は文字通り推定値であり、先ほど表示されていた数値が入っている。
`Std. Error`は推定値それぞれの標準誤差である。
また、`t value`はそれぞれの推定値に対して、帰無仮説を0とした場合のt値が表示されており、それに基づいたp値が入っているのが`Pr(>|t|)`の列である。

ここで`e-16`と表示されているのは10の-16乗を表しており、`<`がついていることから、p値がとても小さいことを表している。
また、p値の大きさに基づいて*（アスタリスクであるが、慣例的にスターと呼ぶ）が振られている。

この結果であれば、切片の推定値は統計的には帰無仮説である$\alpha=0$を棄却できないが、$\beta=0$は有意水準1%であっても棄却することができるということになる。

この仮説検定は「推定された数値が0かどうか」ということを検定する。ある推定値が0かどうかは結果に重要な意味をもたらす。ここでは、気温とアイスクリームの関係を推定しているわけであるが、もし$\beta=0$ならば、気温が何度であろうがアイスクリームの売上に関係ないことになってしまう。

因果関係を推定する上で、興味のある係数（ここでは$\beta$）がゼロかどうか、傾きがあるかどうか、は重要なポイントとなるため、この仮説検定は重要である。

### 見せかけの相関と単回帰分析

上で説明した見せかけの相関のある変数同士であっても、単回帰分析で推定すること自体は可能である。

上でみたように、アイスクリームの売上と水難事故の件数を単回帰分析してみよう。ここでは水難事故の件数を目的変数として推定してみる。

```{r}

reg2 <- lm(accident ~ ice, data = dat_ice) 

summary(reg2)

```
結果を見てみると、傾きの係数は`r round(reg2$coef[2],5)`となっている。
素直に解釈すると、アイスクリームの売上が1万円上がると水難事故件数が約0.1件上がる、もしくは売上が10万円上がると水難事故が約1件増えるということになる。
しかし、上で議論したようにそんな因果関係があるわけではない。しかし、単回帰分析として推定してしまうと、それらしい数字が推定され、統計的にも優位になってしまっている。

だからこそ、単純にデータを単回帰分析して結果を解釈することは危険であり、分析するためにどういうロジックでその仮説が導かれるかを吟味する必要がある。また、その仮説が他の変数などに影響される見せかけの相関の可能性はないかどうかを十分に検討する必要がある。

## 回帰分析の推定方法

回帰分析はどのように推定されるのであろうか。もっと簡単に言い換えれば、どういう基準で散布図に"適切な"線を引くことができるのか。

回帰分析は一般的には**最小二乗法**という方法で推定されている。

上で説明したように、母集団における単回帰モデルは、切片と係数と説明変数（すなわち直線部分）で説明できる部分と、説明できない部分（誤差項）がある。
最小二乗法は、この説明できない部分の二乗の合計が最も小さくなるような直線を引く、というアイデアである。

下の図は、気温とアイスクリームの売上のデータのうち、最初の10個だけを取り出したものである。
各点はそれぞれのデータポイントを表している。引かれている直線は回帰直線であるが、この直線が通っているところと実際のデータポイントとの目的変数の差が「残差」となる。当然ながら、どうやって直線を引くかによって残差は変わるが、もっとも残差の合計が小さくなるところが「適切な」線だという考え方である。

引かれた線よりも上や下にデータポイントが散らばるので、そのまま合計すると打ち消し合ってしまうため、実際の「距離」として測ることが難しい。しかし、二乗すれば負の値も正になるため、二乗してから合計することで直線の上下関係なくどれぐらい離れているかという残差を評価することができる。


```{r, echo=FALSE}
# Load the ggplot2 package
library(ggplot2)

# Create a sample data frame with some data points
set.seed(42)  # For reproducibility
dat_ice_10 <- dat_ice |>
  slice(1:10)

# Perform an Ordinary Least Squares (OLS) regression
reg1_10 <- lm(ice ~ temp, data = dat_ice_10)

# Predict y values based on the model
dat_ice_10$y_pred <- predict(reg1_10)

# Create the ggplot
p <- ggplot(data = dat_ice_10, aes(x = temp, y = ice)) +
  geom_point(size = 3) +    # Plot the data points
  geom_smooth(method = "lm", se = FALSE, color = "blue") +    # Plot the OLS regression line
  geom_segment(aes(x = temp, xend = temp, y = ice, yend = y_pred), size=1, linetype = "dashed", color = "gray") +    # Plot the residuals as dotted lines
  geom_text(aes(x = temp, y = (ice + y_pred) / 2, label = "残差"), hjust = -0.1, vjust = 0.5, size = 3, color = "black", family="Hirakakupro-w3") +  # Label the residuals
  labs(
    title = "最小二乗法と残差",
    x = "気温（℃）",
    y = "アイスクリームの売上（万円）"
  ) +
  theme_minimal(base_family="HiraKakuPro-W3")

# Print the plot
print(p)

```

厳密にどのように推定しているかはここでは省略するが、統計学や計量経済学の教科書を見て理解を進めてほしい。


## 演習問題：単回帰分析

1. `AER`パッケージを読み込む。インストールしていない場合はインストールする。

2. `data()`関数を使って、`CASchools`という`AER`パッケージに付属しているデータを読み込む。これは、カリフォルニア州の学校ごとの学生数などのデータである。

3. `tidyverse`パッケージの関数を使って、学生数`students`と教員数`teachers`の比を計算し、`STR`という変数にする。また、国語`read`と数学`math`を足して２で割ったスコアを`score`という変数にする。新たに作成したデータを`dat_school`として保存する。

4. `ggplot`を用いて、x軸を`STR`, y軸を`score`とする散布図を描く。以下のような図になるはずである（背景色やラベルなどは同じでなくてよい）

```{r, echo=FALSE}
library(AER)

data("CASchools")

dat_school <- CASchools |>
  mutate(STR = students/teachers,
         score = (read+math)/2)

ggplot(data=dat_school, aes(x=STR, y=score)) + 
  geom_point() + 
  theme_bw()

```


5. `STR`を説明変数、`score`を目的変数とする単回帰分析を行い、summary()関数を用いて結果を表示しなさい。

6. 5.の結果を解釈しなさい。
