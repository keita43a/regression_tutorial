# 重回帰分析 {#multipleregression}


## 重回帰分析とは

重回帰分析は、単純に言えば説明変数が２つ以上ある回帰式を用いる回帰分析である。

しかし、重回帰分析は、単純に多くの変数を入れることで、目的変数を説明できる部分が増える、というような目的で用いられるのではない。

特に、実証分析における因果推定では、重回帰分析における係数が、他の説明変数の影響を除いた影響として推定されることが重要である。

## 回帰分析における真のモデル

回帰分析では、そのデータを生み出している**元**となる存在があると考える(専門用語ではData Generating Processと呼ぶ)。

これは、現象を起こすメカニズムが存在し、そのメカニズムは**神のみぞ知る**と考えていると言ってもよい。

私たち分析者は、神のみぞ知るメカニズムに迫ろうとしているのだ。

実際の社会で起こっているメカニズムの本当の姿は（真のモデル）は、神のみぞ知るが、シミュレーションによる仮想世界を作ってその世界の真のメカニズムを知りながら、分析をすることはできる。いわば、仮想世界では神になることができるのだ。

### シミュレーション

#### 準備

まず、multi_reg.Rというスクリプトを作って保存しよう。

そして、以下のパッケージを読み込む。

```{r}
library(tidyverse)
library(fixest)
library(skimr)
```


#### データの生成

今から行うのは、以下のような真のモデルがあると仮定して、データを生成することである。

ここでは、あるスーパーマーケットチェーンのお店ごとのデータを生成するとしよう。このスーパーマーケットチェーンでは全国で300店舗展開しているとする。
300店舗のうち、一部の店舗では広告を出稿することにした。ここで分析しようとしているのは、広告を出すことによって平均的に売上が上がるのかどうかである。

当然ながら売上は広告だけでは決まらない。ここでは、「神」となってデータを生成してみよう。
各店舗$i$の売上は、以下のモデルで決まるとしよう。これが「真のモデル」である。

$$
 Sales_i = \alpha + \beta_1 Ads_i + \beta_2 Age_i + \beta_3 Income_i + \varepsilon_i
$$

$Sales_i$は店舗$i$の売上、$Ads_i$は広告を出したかというダミー変数で出向していれば1, していなければ0を取る。$Age_i$は店長の年齢である。$Income_i$はその店舗が出店している地域の平均所得だとしよう。

単純なモデルであるが売上は、広告、店長の年齢、地域の平均所得で決まるとしよう。

しかし、広告を出すかどうか、という意思決定は**外生的**に決まらない。外生的とは、モデルの外で天から降ってきたように決まることをいう。しかし、この広告を出すかどうかは**内生的**に決まるものだとしよう。モデルの中の変数によって決まるとする。

$$
 Ads_i = I\{100 \leq \gamma_1 Age_i + \gamma_2 Income_i + u_i\}
$$

すこしややこしい数式だが、この数式が言っているのは次のとおりだ。店長の年齢と地域の平均所得で決まる数値が100より大きい店舗では広告を出稿する。


そして、仮想世界の神であるので、このモデルのパラメーターの数値を決めることができる。
以下のようにパラメーターの数値を決めた。

```{r}
# パラメーターの数値
a1<-500
b1<-50
b2<-5
b3<-0.09

g1 <- 1
g2 <- 0.1

N2<-300
```

そして、いよいよデータの生成である。
データの生成には確率的な要素も入れ込むが、再現性を担保するためにシード値を決めておく。


```{r}
# シードの固定
set.seed(3)
```

そして、以下のようにデータを生成する。
少し説明が難しい要素もあるので、ここはコピー&ペーストでよいので自分のスクリプトに貼り付けて実行してみよう。
実行する際は、かならず上の`set.seed(3)`を実行してから実行すること。

```{r}
# シミュレーションデータの作成
dat_sim = tibble(
  shop_ID = 1:N2,
  age = round(runif(N2,25,60)),
  income = round(runif(N2,15,100))*10,
  pop = round(runif(N2,10,1000))*100,
  dogs = round(runif(N2,0,0.5),digits=2),
  u_ads = rnorm(N2,0,sd=10),
  z_ads = round(g1*age+g2*income,digits=1),
  y_ads = z_ads + u_ads,
  ads = ifelse(100 <= y_ads,1,0),
  epsilon = rnorm(N2,sd=20),
  sales = round(a1 + b1*ads + b2*age + b3*income + epsilon,digits=1)
) %>%
  select(!contains("_ads") & !starts_with("u")) %>%
  relocate(ads, .before=age)

```

ここでは、上のモデルで使った変数に加えて、`pop`という地域の人口に当たる変数と、`dogs`という地域の犬を飼っている割合という変数も生成している。

データの記述統計を見てみよう。

```{r}
skim(dat_sim)
```


### 回帰モデルの推定

#### 新たなパッケージの導入

ここで新しいパッケージを導入する。
`fixest`というパッケージをインストールしよう。
インストールするには、RStudioの右下ペーンのPackagesタブからInstallをクリックして名前を指定するか、以下のコードを実行する。

```{r, eval=FALSE}
install.packages("fixest")
```

そして、忘れずにパッケージをロードする。
```{r}
library(fixest)
```

このパッケージは、回帰分析を行うパッケージである。
前章までは回帰分析をRにデフォルトで入っている`lm()`関数で行ってきた。
このパッケージに入っている`feols()`関数は、基本的に同じように回帰分析を行うことができるが、より柔軟にいろんなことができるためこれを使っていく。
また、このパッケージに入っている`etable()`という関数を使うと、回帰分析の結果をよりわかりやすく表示することができる。


#### モデルの推定

ここでの疑問は「広告の出稿は売上増加に貢献するか」であった。

普通のデータなら、真のモデルはわからないが、ここでは我々は神なので真のモデルがわかっている。

まず、このデータから真のモデルと同じモデルを推定してみよう。

```{r}
model_true <- feols(sales ~ ads + age + income, data = dat_sim)

etable(model_true)
```

設定したパラメーターに近い数値が推定されている。

真のモデルを知っていれば広告の効果は50であるとわかる。
また、真のモデルに基づいたデータ分析でも推定値は49.66と非常に近い値が推定されている。

しかし、本当は分析者は真のモデルは知らない。
一般的には、単回帰分析から始めるが、単回帰分析をしてみるとどうなるだろうか。


$$
 Sales_i = \alpha + \beta_1 Ads_i + \varepsilon_i
$$

**練習問題**: 説明変数を広告とした単回帰モデルを推定し、結果を表示させなさい

```{r, echo =FALSE}
model_1 <- feols(sales ~ ads, data = dat_sim)

etable(model_1)
```

推定値は107と出た。これは真の値である50に比べると２倍以上である。
つまり、このモデルでは広告の効果を２倍以上見積もっていることになる。

何度も言うように、本来ならば分析者は真のモデルや真の値を知らない。
そのため、単純に単回帰モデルを分析して、結果を解釈すると「広告の出稿は107万円の売上を増加させる」という間違った結果を得てしまう。

次に、分析者は他の変数を含めてみようと思うかもしれない。
地域の人口が売上に影響を与えていそうだ、という思って次のような重回帰モデルを推定するとしよう。

$$
 Sales_i = \alpha + \beta_1 Ads_i + \beta_4 Pop_i + \varepsilon_i
$$


**練習問題**: 説明変数を広告と人口(`pop`)とした重回帰モデルを推定し、結果を表示させなさい

```{r, echo =FALSE}
model_2 <- feols(sales ~ ads + pop, data = dat_sim)

etable(model_2)
```

結果は、popの係数の数値は非常に小さく、また統計的にゼロである可能性を棄却できなかった。
また、広告の効果も単回帰とは変わらない。

次に、分析者は店長の年齢は経験値などに比例しているので売上に関係があると思ったとする。
そこで、次に店長の年齢`age`を含めたモデルを推定する。

**練習問題**: 説明変数を広告、人口(`pop`)、店長の年齢(`age`)とした重回帰モデルを推定し、結果を表示させなさい

```{r, echo =FALSE}
model_3 <- feols(sales ~ ads + pop + age, data = dat_sim)

etable(model_3)
```

```{r}
models_ads = list()

models_ads[["Model 1"]] = feols(sales ~ ads, se="iid", data=dat_sim)
models_ads[["Model 2"]] = feols(sales ~ ads + age, se="iid", data=dat_sim)
models_ads[["Model 3"]] = feols(sales ~ ads + age + income, se="iid", data=dat_sim)
models_ads[["Model 4"]] = feols(sales ~ ads + age + income + pop, se="iid", data=dat_sim)
models_ads[["Model 5"]] = feols(sales ~ ads + age + income + pop + dogs, se="iid", data=dat_sim)

etable(models_ads)

```


## モデルの当てはまり

### 決定係数

- 最小二乗法では残差二乗和が最小になる。
- しかし、ゼロではない。これは、回帰モデルですべての観測値を完全に予測できているわけではないことを示している。
- 一般的には完全に予測することは不可能である。
- この最小二乗法によって求めたモデルがどの程度データの変動を説明してくれているかを測る指標が**決定係数**。

- 決定係数は残差変動と総変動の比を１から引いたものとして定義される。
- **残差変動**とは、モデルで説明できていないデータの変動である。つまりこれは残差二乗和である。

$$
 \sum_{i=1}^{n}\hat{u}^2_{i}
$$

- 総変動とはデータの目的変数のすべてのばらつきである。つまり、目的変数の平均とすべての観測値の差の二乗和である。

$$
  \sum_{i=1}^{n} (y_{i} - \bar{y}_{i})^2
$$
- 決定係数は**すべての変動のうち、残差変動ではない部分の割合はどれぐらいか？**　すなわち、モデルで説明される変動はどれぐらいか？を測っている。

$$
 R^2 = 1 - \frac{\sum_{i=1}^{n}\hat{u}^2_{i}}{\sum_{i=1}^{n} (y_{i} - \bar{y}_{i})^2}
$$

この数値は、高ければ高いほど、データを説明できている、ということができる。

じゃあ、この数値が高いモデルが「良いモデル」なのかというと、そうとは限らない。
その理由は２つある。
一つは、我々の目的はあくまで因果関係を実証することになる。決定係数は予測が当てはまっているか、というものを測るに過ぎない。
データ上、決定係数が高いが、不要な変数などを含めてしまっている可能性も存在し、それが因果関係を示すパラメータに影響を与えていたら、決定係数が高くても意味がない。

もう一つは、決定係数は説明変数が多ければ多いほど、高くなる傾向にある。
つまり、追加した説明変数に対して説明力（予測を改善する力）がなくても、見かけ上決定係数が上昇するのである。
その欠点を改善したものが次の自由度調整済み決定係数である。

### 自由度調整済み決定係数

自由度調整済み決定係数は、説明変数の数を調整した後での決定係数であり、決定係数と違って説明変数をたくさんなんでも含めれば増加するというものではない。
自由度調整済み決定係数は以下のように定義される。

$$
 R^2_{a} = 1 - \frac{(1-R^2)(n-1)}{n-k-1}
$$
ここで、$n$はサンプルサイズ（データ数）であり、$k$は説明変数の数である。
式を覚える必要はなく、自由度調整済み決定係数が決定係数とどう違うかが理解できていればよい。


